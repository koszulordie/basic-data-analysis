{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... before using this jupyter-notebook\n",
    "\n",
    "# create a conda environment for running the notebook\n",
    "# from the command line\n",
    "\n",
    "$ conda create -n stats_env python=3.7 ipykernel scipy pandas statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berkson's paradox simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(p1, p2, N):\n",
    "\n",
    "    binary_outcomes = [0, 1]\n",
    "    d1 = np.random.choice(binary_outcomes, size=N, p=[1-p1, p1])\n",
    "    d2 = np.random.choice(binary_outcomes, size=N, p=[1-p2, p2])\n",
    "    return d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2 = generate_data(0.1, 0.1, 100)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = [z for z in zip(d1, d2) if (z[0] + z[1] >= 1)]\n",
    "d1_hosp, d2_hosp = tuple(zip(*zipped))\n",
    "d1_hosp, d2_hosp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin-flip experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute logistic regression\n",
    "\n",
    "def logitpval(x, y):\n",
    "    \n",
    "    x = np.array([np.ones_like(x), x])\n",
    "    y = np.array(y)\n",
    "    logit = Logit(y, x.T)\n",
    "    res = logit.fit_regularized(alpha=0.1, disp=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate random binary vectors\n",
    "\n",
    "def generate_data(p1, p2, N):\n",
    "\n",
    "    binary_outcomes = [0, 1]\n",
    "    d1 = np.random.choice(binary_outcomes, size=N, p=[1-p1, p1])\n",
    "    d2 = np.random.choice(binary_outcomes, size=N, p=[1-p2, p2])\n",
    "    return d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random binary vectors (single step)\n",
    "# with prescribed prevalences\n",
    "\n",
    "d1, d2 = generate_data(0.1, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out the logistic regression p-val\n",
    "# p-value and log-odds ratio\n",
    "\n",
    "res = logitpval(d1, d2)\n",
    "pval, lor = res.pvalues[1], res.params[1]\n",
    "pval, lor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out many simulations generate many results\n",
    "\n",
    "n_sim = 100\n",
    "y, p = [], []\n",
    "for _ in range(n_sim):\n",
    "    d1, d2 = generate_data(0.1, 0.1, 1000)\n",
    "    res = logitpval(d1, d2)\n",
    "    p.append(res.pvalues[1])\n",
    "    y.append(res.params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of log-odds ratios for many simulations\n",
    "\n",
    "def jitter(x, sigma=0.01):\n",
    "    \n",
    "    eps = np.random.normal(0, sigma, size=len(x))\n",
    "    return x + eps\n",
    "\n",
    "plt.boxplot(y, showfliers=False)\n",
    "plt.scatter(jitter(np.ones(len(y))), y, alpha=0.5)\n",
    "plt.ylabel('log OR')\n",
    "plt.xticks([])\n",
    "plt.title(f'Boxplot: {n_sim} simulations\\n p1=p2=0.1 N=1000')\n",
    "plt.savefig('./boxplot_full_population.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fit the logistic regression with\n",
    "# restricted vectors, i.e.,\n",
    "# by selecting those samples with at least one hit\n",
    "\n",
    "y, p = [], []\n",
    "for _ in range(100):\n",
    "    d1, d2 = generate_data(0.1, 0.1, 1000)\n",
    "    zipped = [z for z in zip(d1, d2) if (z[0] + z[1] >= 1)]\n",
    "    d1, d2 = tuple(map(np.array, zip(*zipped)))\n",
    "    res = logitpval(d1, d2)\n",
    "    p.append(res.pvalues[1])\n",
    "    y.append(res.params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(y, showfliers=False)\n",
    "plt.scatter(jitter(np.ones(len(y))), y, alpha=0.5)\n",
    "plt.ylabel('log OR')\n",
    "plt.xticks([])\n",
    "plt.title(f'Boxplot: {n_sim} simulations: Restricted Set\\n p1=p2=0.1 N=1000')\n",
    "plt.savefig('./boxplot_selected_population.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the last pair of\n",
    "# binary vectors that has been generated\n",
    "# it may seem as if the diseases repel each other...\n",
    "\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tea testing challenge a.k.a. Fisher test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "\n",
    "[M, n, N] = [40, 20, 20]  # M: total cups of tea\n",
    "                          # N: true milk-first cups of tea\n",
    "                          # n: cups of tea chosen at the experiment\n",
    "\n",
    "rv = hypergeom(M, n, N)\n",
    "x = np.arange(0, n+1)\n",
    "pmf_successes = rv.pmf(x)  # vector of probability masses for each\n",
    "                           # possible outcome of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the discrete distribution of all possible outcomes\n",
    "# for the lady tea challenge\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, pmf_successes, 'bo')\n",
    "ax.vlines(x, 0, pmf_successes, lw=2)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel('a = # correctly predicted milk-first cups of tea')\n",
    "ax.set_ylabel('Probability of Contingency Table')\n",
    "plt.savefig('./lady_tasting.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the probability mass comprising\n",
    "# the outcomes at least as good as k = 12 successes?\n",
    "\n",
    "sum(pmf_successes[12:21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple test correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benjamini-Hochberg FDR\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "pval_collection = [0.04, 0.15, 0.9, 0.01, 0.64, 0.07, 0.15, 0.64, 0.3]\n",
    "qval_collection = multipletests(pval_collection, method='fdr_bh')[1]\n",
    "qval_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Material: my first regression survival kit in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "# carry out linear regression on a synthetic dataset\n",
    "# with known dependencies between covariate and response\n",
    "# plus some noise\n",
    "\n",
    "x = np.random.normal(20, 5, size=50)\n",
    "y = 0.1 * x + np.random.normal(0, 1., size=50)\n",
    "x = np.array([x, np.ones(len(x))])\n",
    "model = OLS(y, x.T)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "\n",
    "plt.scatter(x[0,:], y, alpha=0.7)\n",
    "plt.xlabel('temperature')\n",
    "plt.ylabel('growth rate percentage')\n",
    "plt.savefig('./linear_regression.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "# with fitting line\n",
    "\n",
    "X = np.linspace(5, 35, num=100)\n",
    "Y = res.params[0] * X + res.params[1]\n",
    "plt.plot(X, Y, 'r--')\n",
    "plt.scatter(x[0,:], y, alpha=0.7)\n",
    "plt.xlabel('temperature')\n",
    "plt.ylabel('growth rate percentage')\n",
    "plt.savefig('./linear_regression_line.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out multivariable linear regression\n",
    "# on synthetic dataset with known dependencies\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "x = np.random.normal(20, 5, size=50)\n",
    "pH = np.random.normal(7, 2, size=50)\n",
    "p = np.random.normal(1, 0.1, size=50)\n",
    "y = 0.1 * x + pH + 2.5 * p + np.random.normal(0, 1., size=50)\n",
    "x = np.array([x, pH, p, np.ones(len(x))])\n",
    "model = OLS(y, x.T)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic students data\n",
    "\n",
    "shape, scale = 30, 1\n",
    "hours = np.random.gamma(shape=shape, scale=scale, size=100)\n",
    "\n",
    "# true params of the model\n",
    "\n",
    "a = 1 / 5\n",
    "b = -6\n",
    "\n",
    "# synthetic probabilities\n",
    "\n",
    "probs = 1 / (1 + np.exp((-1) * (hours * a + b)))\n",
    "outcome = np.random.binomial(1, size=len(probs), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "\n",
    "plt.scatter(hours, outcome, alpha=0.6)\n",
    "plt.yticks([0, 1], ['fail', 'pass'])\n",
    "plt.xlabel('hours of study')\n",
    "plt.savefig('./logistic.png', dpi=200)\n",
    "plt.title('Test Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with true logistic fitting curve\n",
    "\n",
    "x = np.linspace(10, 50, num=100)\n",
    "probs = 1 / (1 + np.exp((-1) * (x * a + b)))\n",
    "plt.plot(x, probs, 'black')\n",
    "plt.scatter(hours, outcome, alpha=0.6)\n",
    "plt.xlabel('hours of study')\n",
    "plt.ylabel('probability to pass')\n",
    "plt.savefig('./logistic_line.png', dpi=200)\n",
    "plt.title('Test Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out logistic regression\n",
    "\n",
    "x = np.array([np.ones_like(hours), hours])\n",
    "y = np.array(outcome)\n",
    "logit = Logit(y, x.T)\n",
    "res = logit.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lady tea challenge revisited\n",
    "# carry out regression with logistic regression\n",
    "\n",
    "y = np.array([1, 1, 1, 1, 0, 0, 0, 0])\n",
    "x = np.array([1, 1, 1, 0, 1, 0, 0, 0])\n",
    "x = np.array([x, np.ones(len(x))])\n",
    "logit = Logit(y, x.T)\n",
    "res = logit.fit()\n",
    "res.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stats_env]",
   "language": "python",
   "name": "conda-env-stats_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
